"""
Celery Tasks ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RPA ‡πÅ‡∏•‡∏∞ News Intelligence
"""
from celery import shared_task
from datetime import datetime, date
import logging

logger = logging.getLogger(__name__)


@shared_task(name='rpa_bot.tasks.run_rpa_task')
def run_rpa_task_async(task_id):
    """‡∏£‡∏±‡∏ô RPA Task ‡πÅ‡∏ö‡∏ö Async"""
    from .models import RPATask
    from .rpa_runner import run_rpa_task

    try:
        task = RPATask.objects.get(pk=task_id)
        logger.info(f"Starting RPA Task: {task.name} (ID: {task_id})")

        run_rpa_task(task)

        logger.info(f"RPA Task completed: {task.name} (ID: {task_id})")
        return {
            'success': True,
            'task_id': task_id,
            'status': task.status
        }

    except RPATask.DoesNotExist:
        logger.error(f"RPA Task not found: ID {task_id}")
        return {
            'success': False,
            'error': 'Task not found'
        }

    except Exception as e:
        logger.error(f"Error running RPA Task {task_id}: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }


@shared_task(name='rpa_bot.tasks.scrape_all_news')
def scrape_all_news():
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß‡∏ó‡∏∏‡∏Å‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà - Task ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Celery Beat"""
    from .news_scraper import NewsScraperService

    try:
        logger.info("üîç Starting news scraping task...")

        scraper = NewsScraperService()

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡∏´‡∏°‡∏ß‡∏î
        articles_by_category = scraper.scrape_all_categories()

        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        saved_articles = scraper.save_articles(articles_by_category)

        logger.info(f"‚úÖ News scraping completed! Saved {len(saved_articles)} articles")

        return {
            'success': True,
            'articles_count': len(saved_articles),
            'timestamp': datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"‚ùå Error scraping news: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }


@shared_task(name='rpa_bot.tasks.generate_daily_report')
def generate_daily_report():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô - Task ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Celery Beat"""
    from .ai_summarizer import AISummarizerService
    from .models import NewsArticle

    try:
        logger.info("üìä Starting daily report generation...")

        summarizer = AISummarizerService()

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á AI Summary ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        articles_without_summary = NewsArticle.objects.filter(
            ai_summary__isnull=True,
            published_at__date=date.today()
        )

        for article in articles_without_summary[:50]:  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÑ‡∏ß‡πâ 50 ‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡∏Ñ‡∏£‡∏±‡πâ‡∏á
            summarizer.summarize_article(article)

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô
        report = summarizer.generate_daily_report()

        if report:
            logger.info(f"‚úÖ Daily report generated successfully for {report.report_date}")

            return {
                'success': True,
                'report_id': report.id,
                'report_date': report.report_date.isoformat()
            }
        else:
            logger.error("‚ùå Failed to generate daily report")
            return {
                'success': False,
                'error': 'Report generation failed'
            }

    except Exception as e:
        logger.error(f"‚ùå Error generating daily report: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }


@shared_task(name='rpa_bot.tasks.send_daily_report')
def send_daily_report():
    """‡∏™‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ß‡∏±‡∏ô - Task ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Celery Beat"""
    from .ai_summarizer import AISummarizerService
    from .models import DailyReport

    try:
        logger.info("üì® Starting daily report sending...")

        # ‡∏´‡∏≤‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏™‡πà‡∏á
        report = DailyReport.objects.filter(
            report_date=date.today(),
            is_completed=True,
            is_sent=False
        ).first()

        if not report:
            logger.warning("‚ö†Ô∏è No report found to send today")
            return {
                'success': False,
                'error': 'No report found'
            }

        summarizer = AISummarizerService()
        success = summarizer.send_report(report)

        if success:
            logger.info(f"‚úÖ Daily report sent successfully for {report.report_date}")
            return {
                'success': True,
                'report_id': report.id,
                'sent_at': report.sent_at.isoformat()
            }
        else:
            logger.error("‚ùå Failed to send daily report")
            return {
                'success': False,
                'error': 'Report sending failed'
            }

    except Exception as e:
        logger.error(f"‚ùå Error sending daily report: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }


@shared_task(name='rpa_bot.tasks.daily_news_intelligence')
def daily_news_intelligence():
    """
    Task ‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Daily News Intelligence
    ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡∏ß‡∏±‡∏ô‡πÄ‡∏ß‡∏•‡∏≤ 10:00 ‡∏ô.
    1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß
    2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
    3. ‡∏™‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
    """
    try:
        logger.info("ü§ñ Starting Daily News Intelligence Bot...")

        # Step 1: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß
        logger.info("Step 1/3: Scraping news...")
        scrape_result = scrape_all_news()

        if not scrape_result.get('success'):
            raise Exception(f"News scraping failed: {scrape_result.get('error')}")

        # Step 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
        logger.info("Step 2/3: Generating report...")
        report_result = generate_daily_report()

        if not report_result.get('success'):
            raise Exception(f"Report generation failed: {report_result.get('error')}")

        # Step 3: ‡∏™‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
        logger.info("Step 3/3: Sending report...")
        send_result = send_daily_report()

        if not send_result.get('success'):
            raise Exception(f"Report sending failed: {send_result.get('error')}")

        logger.info("‚úÖ Daily News Intelligence completed successfully!")

        return {
            'success': True,
            'scrape_result': scrape_result,
            'report_result': report_result,
            'send_result': send_result,
            'timestamp': datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"‚ùå Daily News Intelligence failed: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }


@shared_task(name='rpa_bot.tasks.cleanup_old_articles')
def cleanup_old_articles(days=30):
    """‡∏•‡∏ö‡∏ö‡∏ó‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô X ‡∏ß‡∏±‡∏ô"""
    from .models import NewsArticle
    from datetime import timedelta

    try:
        cutoff_date = datetime.now() - timedelta(days=days)

        deleted_count, _ = NewsArticle.objects.filter(
            published_at__lt=cutoff_date
        ).delete()

        logger.info(f"üóëÔ∏è Cleaned up {deleted_count} old articles")

        return {
            'success': True,
            'deleted_count': deleted_count
        }

    except Exception as e:
        logger.error(f"‚ùå Error cleaning up articles: {str(e)}")
        return {
            'success': False,
            'error': str(e)
        }
