import pyautogui
import webbrowser
import time
import os
from urllib.parse import quote_plus
from PIL import Image
import pytesseract

# ============================================
# Stock Bot Advanced - macOS Version (No API Required)
# Advanced web scraping with OCR text extraction
# ============================================

print("=" * 80)
print("ü§ñ Stock Bot Advanced - macOS Version")
print("=" * 80)
print("üì∏ ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û + OCR Text Extraction (‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ API)")
print("=" * 80)

# --- 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ---
print("\nüìã ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:")
print("   1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ (Dynamic Search)")
print("   2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢ (Stock Focus)")
print("   3. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏≠‡∏á (Custom Query)")

mode = input("\nüî¢ ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î (1-3): ").strip()

if mode == "1":
    search_query = input("\nüîç ‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: ").strip()
elif mode == "2":
    search_query = "‡∏£‡∏≤‡∏Ñ‡∏≤‡∏´‡∏∏‡πâ‡∏ô‡πÑ‡∏ó‡∏¢‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ"
elif mode == "3":
    search_query = input("\nüîç ‡πÉ‡∏™‡πà‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: ").strip()
else:
    print("‚ùå ‡πÇ‡∏´‡∏°‡∏î‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
    exit(1)

num_websites = int(input("\nüåê ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏ä‡∏° (1-10): ").strip() or "3")

print(f"\n‚úÖ ‡πÇ‡∏´‡∏°‡∏î: {mode}")
print(f"üîç ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {search_query}")
print(f"üåê ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå: {num_websites}")

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö permissions ‡∏ö‡∏ô macOS
print("\n‚ö†Ô∏è  ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï Accessibility & Screen Recording")
print("System Settings > Privacy & Security > Accessibility")
print("System Settings > Privacy & Security > Screen Recording")
print("=" * 80)

print("\n‚è∞ ‡∏ö‡∏≠‡∏ó‡∏à‡∏∞‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÉ‡∏ô 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ...")
time.sleep(5)

# --- 2. Helper Functions ---
def extract_text_from_image(image_path):
    """‡πÉ‡∏ä‡πâ OCR ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û"""
    try:
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á tesseract ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
        text = pytesseract.image_to_string(Image.open(image_path), lang='eng+tha')
        return text.strip()
    except Exception as e:
        return f"‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏î‡πâ (‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á tesseract: brew install tesseract)"

def analyze_screenshot_locally(image_path, query):
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏†‡∏≤‡∏û‡πÅ‡∏ö‡∏ö local (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ API)"""
    print(f"\nüìù ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û...")

    text = extract_text_from_image(image_path)

    analysis = {
        'extracted_text': text,
        'keywords_found': [],
        'numbers_found': [],
        'urls_found': []
    }

    # ‡∏´‡∏≤ keywords
    keywords = ['‡∏´‡∏∏‡πâ‡∏ô', 'stock', '‡∏£‡∏≤‡∏Ñ‡∏≤', 'price', '‡∏î‡∏±‡∏ä‡∏ô‡∏µ', 'index', 'SET', '‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô', '‡∏•‡∏î‡∏•‡∏á']
    for keyword in keywords:
        if keyword.lower() in text.lower():
            analysis['keywords_found'].append(keyword)

    # ‡∏´‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
    import re
    numbers = re.findall(r'\d+[\.,]\d+|\d+', text)
    analysis['numbers_found'] = numbers[:10]  # ‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà 10 ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å

    # ‡∏´‡∏≤ URLs
    urls = re.findall(r'https?://[^\s]+', text)
    analysis['urls_found'] = urls

    return analysis

# --- 3. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ---
print(f"\nüîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {search_query}")
encoded_search = quote_plus(search_query)
search_url = f"https://www.google.com/search?q={encoded_search}"

# ‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå
print("\nüåê ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ß‡πá‡∏ö‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå...")
webbrowser.open(search_url)
time.sleep(8)

# ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
screen_width, screen_height = pyautogui.size()
print(f"üìê ‡∏Ç‡∏ô‡∏≤‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠: {screen_width}x{screen_height}")

# ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
print("\nüì∏ ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤...")
screenshot = pyautogui.screenshot()
search_results_path = "local_search_results.png"
screenshot.save(search_results_path)
print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {search_results_path}")

# ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏ô‡πâ‡∏≤‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
print("\nüîç ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏ô‡πâ‡∏≤‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤...")
search_analysis = analyze_screenshot_locally(search_results_path, search_query)

print("\n" + "=" * 80)
print("üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤:")
print("=" * 80)
print(f"üîë ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏û‡∏ö: {', '.join(search_analysis['keywords_found']) if search_analysis['keywords_found'] else '‡πÑ‡∏°‡πà‡∏û‡∏ö'}")
print(f"üî¢ ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏û‡∏ö: {', '.join(search_analysis['numbers_found'][:5]) if search_analysis['numbers_found'] else '‡πÑ‡∏°‡πà‡∏û‡∏ö'}")

# --- 4. ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå ---
all_results = []

# ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
search_positions = [
    (screen_width // 2, int(screen_height * 0.40)),
    (screen_width // 2, int(screen_height * 0.52)),
    (screen_width // 2, int(screen_height * 0.64)),
    (screen_width // 2, int(screen_height * 0.76)),
    (screen_width // 2, int(screen_height * 0.88)),
]

for i in range(min(num_websites, len(search_positions))):
    print(f"\n{'='*80}")
    print(f"üîó [{i+1}/{num_websites}] ‡πÄ‡∏¢‡∏µ‡πà‡∏¢‡∏°‡∏ä‡∏°‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà {i+1}")
    print(f"{'='*80}")

    try:
        # ‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå
        print(f"üñ±Ô∏è  ‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå...")
        pyautogui.click(search_positions[i][0], search_positions[i][1])
        time.sleep(6)

        # ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å
        screenshot = pyautogui.screenshot()
        website_path = f"local_website_{i+1:02d}_main.png"
        screenshot.save(website_path)
        print(f"üì∏ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {website_path}")

        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå
        website_analysis = analyze_screenshot_locally(website_path, search_query)

        print("\n" + "-" * 80)
        print(f"üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà {i+1}:")
        print("-" * 80)
        print(f"üîë ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {', '.join(website_analysis['keywords_found'][:10]) if website_analysis['keywords_found'] else '‡πÑ‡∏°‡πà‡∏û‡∏ö'}")
        print(f"üî¢ ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç: {', '.join(website_analysis['numbers_found'][:10]) if website_analysis['numbers_found'] else '‡πÑ‡∏°‡πà‡∏û‡∏ö'}")
        print(f"üîó URLs: {len(website_analysis['urls_found'])} links")
        print("-" * 80)

        all_results.append({
            'website_num': i+1,
            'analysis': website_analysis
        })

        # Scroll ‡∏î‡∏π‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
        print(f"\nüìú Scroll ‡∏î‡∏π‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°...")
        pyautogui.scroll(-3)
        time.sleep(2)

        # ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏´‡∏•‡∏±‡∏á scroll
        screenshot = pyautogui.screenshot()
        scrolled_path = f"local_website_{i+1:02d}_scrolled.png"
        screenshot.save(scrolled_path)
        print(f"üì∏ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å: {scrolled_path}")

        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏±‡∏á scroll
        scrolled_analysis = analyze_screenshot_locally(scrolled_path, search_query)
        print(f"üîë ‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: {', '.join(scrolled_analysis['keywords_found'][:5]) if scrolled_analysis['keywords_found'] else '‡πÑ‡∏°‡πà‡∏û‡∏ö'}")

        # ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
        if i < num_websites - 1:
            print(f"\n‚¨ÖÔ∏è  ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏ô‡πâ‡∏≤‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤...")
            pyautogui.hotkey('command', '[')
            time.sleep(3)

    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        continue

# --- 5. ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ---
print("\n" + "=" * 80)
print("üìä ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
print("=" * 80)

# ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
report_path = "local_analysis_report.txt"
with open(report_path, "w", encoding="utf-8") as f:
    f.write("=" * 80 + "\n")
    f.write("ü§ñ Stock Bot Local Analysis Report\n")
    f.write("=" * 80 + "\n\n")
    f.write(f"üîç ‡∏Ñ‡∏≥‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: {search_query}\n")
    f.write(f"üìÖ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
    f.write(f"üåê ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå: {num_websites}\n\n")

    f.write("=" * 80 + "\n")
    f.write("üìä ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏ô‡πâ‡∏≤‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤\n")
    f.write("=" * 80 + "\n\n")
    f.write(f"‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {', '.join(search_analysis['keywords_found'])}\n")
    f.write(f"‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç: {', '.join(search_analysis['numbers_found'][:10])}\n\n")

    for result in all_results:
        f.write("=" * 80 + "\n")
        f.write(f"üåê ‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå‡∏ó‡∏µ‡πà {result['website_num']}\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: {', '.join(result['analysis']['keywords_found'])}\n")
        f.write(f"‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç: {', '.join(result['analysis']['numbers_found'][:20])}\n")
        f.write(f"URLs: {len(result['analysis']['urls_found'])} links\n\n")

print(f"\n‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà: {report_path}")

# ‡∏ô‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á
created_files = [f for f in os.listdir('.') if f.startswith('local_') and f.endswith('.png')]
created_files.sort()

print(f"\nüìÅ ‡πÑ‡∏ü‡∏•‡πå‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á: {len(created_files)} ‡πÑ‡∏ü‡∏•‡πå")
for filename in created_files[:5]:
    size = os.path.getsize(filename) / 1024
    print(f"   ‚úÖ {filename} ({size:.2f} KB)")
if len(created_files) > 5:
    print(f"   ... ‡πÅ‡∏•‡∏∞‡∏≠‡∏µ‡∏Å {len(created_files) - 5} ‡πÑ‡∏ü‡∏•‡πå")

print(f"\nüìÑ ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå: {report_path}")
print(f"üìÇ ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á: {os.path.abspath('.')}")

print("\nüí° ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏ó‡∏ó‡∏≥:")
print("   1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Google")
print("   2. ‡∏ñ‡πà‡∏≤‡∏¢‡∏†‡∏≤‡∏û‡∏´‡∏ô‡πâ‡∏≤‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤")
print("   3. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ OCR (‡∏ñ‡πâ‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á tesseract)")
print("   4. ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ä‡∏°‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå")
print("   5. ‡∏™‡∏£‡∏∏‡∏õ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô")

print("\nüé® ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥:")
print("   ‚úÖ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ API")
print("   ‚úÖ ‡∏ü‡∏£‡∏µ 100%")
print("   ‚úÖ OCR Text Extraction (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ tesseract)")
print("   ‚úÖ Keyword Detection")
print("   ‚úÖ Number Extraction")

print("\nüí° ‡πÄ‡∏Ñ‡∏•‡πá‡∏î‡∏•‡∏±‡∏ö:")
print("   ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Tesseract ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°:")
print("   brew install tesseract")
print("   brew install tesseract-lang")

print("\n" + "=" * 80)
print("üéâ ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
print("=" * 80)
